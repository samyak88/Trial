{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spell_similar.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpfuVajL-Nls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "!pip install fuzzywuzzy\n",
        "!pip install python-Levenshtein\n",
        "from fuzzywuzzy import fuzz\n",
        "from fuzzywuzzy import process\n",
        "!pip install swifter\n",
        "import swifter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "if8eSNtbSgKb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9bbf1f6a-cbd8-4f06-d406-e33f9fcd2bd9"
      },
      "source": [
        "def similiar(col):\n",
        "    uniq = list(col.value_counts().index)[::-1]          # listing all unique levels in increasing order of frequency \n",
        "    uniq_values = list(col.value_counts())[::-1]         # listing count of all unique level in increasing order\n",
        "    idx = (np.abs(np.asarray(uniq_values) - col.count()*0.05)).argmin()  \n",
        "    # index of level which have frequency of about 5%, as a spelling mistake is unlikely to have more than 5% \n",
        "    new_dict={}          # dictionary for storing the mapping of incorrect spelling as key and correct value as value\n",
        "\n",
        "    for i in range(idx):\n",
        "        l = uniq[i+1:][::-1]      # for faster search we start for levels having largest frequency, hence reversed list\n",
        "        for j in l:\n",
        "            if fuzz.token_sort_ratio(uniq[i], j)> 67 :       # token sort ratio gives similarity coefficient in range(0-100)\n",
        "                new_dict[uniq[i]]=j\n",
        "                break\n",
        "\n",
        "    return col.map(new_dict).fillna(col)\n",
        "\n",
        "\n",
        "obj_cols = list(df.dtypes[df.dtypes == np.object].index) \n",
        "col_uni = df[obj_cols].nunique()/df[obj_cols].count()\n",
        "df[list(col_uni[0.15>col_uni].index)] = df[list(col_uni[0.15>col_uni].index)].swifter.apply(similiar)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'\\nobj_cols = list(df.dtypes[df.dtypes == np.object].index) \\ncol_uni = df[obj_cols].nunique()/df[obj_cols].count()\\ndf[list(col_uni[0.15>col_uni].index)] = df[list(col_uni[0.15>col_uni].index)].swifter.apply(similiar)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    }
  ]
}